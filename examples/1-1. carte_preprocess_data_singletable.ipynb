{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing raw data\n",
    "In this example, we preprocess an exemplary tabular data. The dataset is the Wine Poland dataset, which contains information about wines on the polish market. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the current working directory and import packages\n",
    "import os\n",
    "from pathlib import Path\n",
    "os.chdir(Path().cwd().parent)\n",
    "\n",
    "import json\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from configs.directory import config_directory\n",
    "from configs.carte_datalist import carte_datalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define necessary functions\n",
    "\n",
    "def _drop_high_null(data, proportion=0.5):\n",
    "    \"\"\"Drop columns with high fraction of missing values\"\"\"\n",
    "    null_num = np.array([data[col].isnull().sum() for col in data.columns])\n",
    "    null_crit = int(len(data) * proportion)\n",
    "    null_col = list(data.columns[null_num > null_crit])\n",
    "    return data.drop(columns=null_col)\n",
    "\n",
    "def _drop_single_unique(data):\n",
    "    \"\"\"Drop columns with single unique values.\"\"\"\n",
    "    num_unique_cols = [col for col in data.columns if data[col].nunique() == 1]\n",
    "    return data.drop(columns=num_unique_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic info\n",
    "target_name = \"price\"\n",
    "entity_name = \"name\"\n",
    "task = \"regression\"\n",
    "repeated = False\n",
    "# preprocess\n",
    "data.dropna(subset=target_name, inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data[target_name] = np.log10(data[target_name])\n",
    "data[\"vegan\"] = data[\"vegan\"].astype(str)\n",
    "data[\"natural\"] = data[\"natural\"].astype(str)\n",
    "data[\"vintage\"] = data[\"vintage\"].astype(str)\n",
    "data[\"vintage\"] = data[\"vintage\"].str[:4]\n",
    "temp = data[\"vintage\"].copy()\n",
    "temp[temp == \"nan\"] = np.nan\n",
    "data[\"vintage\"] = temp\n",
    "data[\"volume\"] = data[\"volume\"]*1000\n",
    "data = _drop_high_null(data)\n",
    "data = _drop_single_unique(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic info\n",
    "target_name = \"popularity\"\n",
    "entity_name = \"track\"\n",
    "task = \"classification\"\n",
    "repeated = False\n",
    "# preprocess\n",
    "data.dropna(subset=target_name, inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data = _drop_high_null(data)\n",
    "data = _drop_single_unique(data)\n",
    "drop_cols = []\n",
    "drop_cols.append(\"uri\")\n",
    "data.drop(columns=drop_cols, inplace=True)\n",
    "data[\"time_signature\"] = data[\"time_signature\"].astype(\"str\")\n",
    "data[\"sections\"] = data[\"sections\"].astype(\"str\")\n",
    "data[\"key\"] = data[\"key\"].astype(\"str\")\n",
    "data[\"duration_ms\"] = data[\"duration_ms\"].astype(\"float\")\n",
    "temp = data[\"mode\"].copy()\n",
    "mapping = {1: \"Major\", 0: \"Minor\"}\n",
    "temp = temp.map(mapping)\n",
    "data[\"mode\"] = temp"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
