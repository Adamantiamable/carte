{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example for running CARTE on multi-tables (joint learning)\n",
    "In this example, we run CARTE for the multi-table task. We continue the example with the Wine Poland dataset, which contains information about wines on the polish market. The task is to predict the price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n"
     ]
    }
   ],
   "source": [
    "# Set the current working directory and import packages\n",
    "import os\n",
    "from pathlib import Path\n",
    "os.chdir(Path().cwd().parent)\n",
    "\n",
    "import torch\n",
    "import json\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler\n",
    "from src.carte_table_to_graph import Table2GraphTransformer\n",
    "from src.carte_estimator import CARTERegressor, CARTEMultitableRegressor\n",
    "from configs.directory import config_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define necessary functions\n",
    "\n",
    "def _load_data(data_name):\n",
    "    \"\"\"Load the preprocessed data.\"\"\"\n",
    "    data_pd_dir = f\"{config_directory['data_singletable']}/{data_name}/raw.parquet\"\n",
    "    data_pd = pd.read_parquet(data_pd_dir)\n",
    "    data_pd.fillna(value=np.nan, inplace=True)\n",
    "    config_data_dir = f\"{config_directory['data_singletable']}/{data_name}/config_data.json\"\n",
    "    filename = open(config_data_dir)\n",
    "    config_data = json.load(filename)\n",
    "    filename.close()\n",
    "    return data_pd, config_data\n",
    "\n",
    "def _transform_to_graph(data, config_data):\n",
    "    \"\"\"Transform to graph.\"\"\"\n",
    "    graph_transformer = Table2GraphTransformer()\n",
    "    X_original = data.drop(columns=config_data[\"target_name\"])\n",
    "    y_original = data[config_data[\"target_name\"]]\n",
    "    y_original = np.array(y_original)\n",
    "    X_carte = graph_transformer.fit_transform(X=X_original, y=y_original)\n",
    "    return X_carte\n",
    "\n",
    "\n",
    "def _set_split(data, data_config, num_train, random_state):\n",
    "    \"\"\"Set train/test split given the random state.\"\"\"\n",
    "    target_name = data_config[\"target_name\"]\n",
    "    X = data.drop(columns=target_name)\n",
    "    y = data[target_name]\n",
    "    y = np.array(y)\n",
    "\n",
    "    if data_config[\"repeated\"]:\n",
    "        entity_name = data_config[\"entity_name\"]\n",
    "    else:\n",
    "        entity_name = np.arange(len(y))\n",
    "\n",
    "    groups = np.array(data.groupby(entity_name).ngroup())\n",
    "    num_groups = len(np.unique(groups))\n",
    "    gss = GroupShuffleSplit(\n",
    "        n_splits=1,\n",
    "        test_size=int(num_groups - num_train),\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    idx_train, idx_test = next(iter(gss.split(X=y, groups=groups)))\n",
    "\n",
    "    X_train, X_test = X.iloc[idx_train], X.iloc[idx_test]\n",
    "    y_train, y_test = y[idx_train], y[idx_test]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def _prepare_carte(\n",
    "    data_t,\n",
    "    data_s_total,\n",
    "    config_data_t,\n",
    "    config_data_s_total,\n",
    "    num_train,\n",
    "    random_state,\n",
    "):\n",
    "\n",
    "    # Preprocess target data\n",
    "    Xt = data_t.copy()\n",
    "    Xt_train, Xt_test, yt_train, yt_test = _set_split(\n",
    "        Xt,\n",
    "        config_data_t,\n",
    "        num_train,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    graph_transformer = Table2GraphTransformer()\n",
    "    Xt_carte_train = graph_transformer.fit_transform(X=Xt_train, y=yt_train)\n",
    "    Xt_carte_test = graph_transformer.transform(Xt_test)\n",
    "    for data in Xt_carte_train:\n",
    "        data.domain = 0\n",
    "    for data in Xt_carte_test:\n",
    "        data.domain = 0\n",
    "\n",
    "    task = config_data_t[\"task\"]\n",
    "    if task == \"regression\":\n",
    "        # Set power_transformer for targets\n",
    "        scaler_t = PowerTransformer()\n",
    "        scaler_t.fit(np.array(yt_train).reshape(-1, 1))\n",
    "        scaler_t_std = StandardScaler()\n",
    "        scaler_t_std.fit(np.array(yt_train).reshape(-1, 1))\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # Preprocess source data\n",
    "    Xs_carte = dict()\n",
    "    domain_marker = 1\n",
    "    for data_name in data_s_total.keys():\n",
    "        data_s = data_s_total[data_name]\n",
    "        config_s = config_data_s_total[data_name]\n",
    "        Xs_carte_temp = _transform_to_graph(data_s, config_s)\n",
    "        ys = np.array([data.y.cpu().detach().numpy() for data in Xs_carte_temp])\n",
    "        g_idx = np.array([data.g_idx for data in Xs_carte_temp])\n",
    "        # preprocess target for source data\n",
    "        if task == \"regression\":\n",
    "            if config_data_s_total[data_name][\"task\"] == \"classification\":\n",
    "                scaler_s = StandardScaler()\n",
    "                ys_scaled = scaler_s.fit_transform(ys)\n",
    "                ys_train = scaler_t_std.inverse_transform(ys_scaled)\n",
    "            else:\n",
    "                scaler_s = PowerTransformer()\n",
    "                ys_scaled = scaler_s.fit_transform(ys)\n",
    "                ys_train = scaler_t.inverse_transform(ys_scaled)\n",
    "            ys_train = ys_train.squeeze()\n",
    "        else:\n",
    "            ys_train = ys.copy()\n",
    "            ys_train = ys_train.squeeze()\n",
    "            if config_data_s_total[data_name][\"task\"] == \"regression\":\n",
    "                med_value = statistics.median(ys_train)\n",
    "                ys_train[ys_train < med_value] = 0\n",
    "                ys_train[ys_train != 0] = 1\n",
    "\n",
    "        # exclude null targets\n",
    "        mask = np.isnan(ys_train)\n",
    "        keep_idx = g_idx[~mask]\n",
    "        Xs_carte_ = [Xs_carte_temp[x] for x in keep_idx]\n",
    "        ys_train = ys_train[~mask]\n",
    "        for i in range(len(Xs_carte_)):\n",
    "            Xs_carte_[i].y = torch.tensor([ys_train[i]])\n",
    "            Xs_carte_[i].domain = domain_marker\n",
    "        Xs_carte[data_name] = Xs_carte_\n",
    "        domain_marker += 1\n",
    "\n",
    "    return Xt_carte_train, Xt_carte_test, Xs_carte, yt_train, yt_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For joint-learning, we preprocess the target table exactly same as with the singletable case (fit_transform/transform), but for source data, we form a dictionary with containing each source separately. Moreover, we include a domain marker, indicating where the data is originating from.\n",
    "\n",
    "Let first run the singletable case for the Wine Poland dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "Model No. xx:   9%|▉         | 46/500 [00:10<01:47,  4.21it/s]\n",
      "Model No. xx:  11%|█         | 54/500 [00:13<01:49,  4.07it/s]\n",
      "Model No. xx:  10%|█         | 51/500 [00:13<02:01,  3.69it/s]\n",
      "Model No. xx:  10%|█         | 51/500 [00:13<02:02,  3.66it/s]\n",
      "Model No. xx:  12%|█▏        | 62/500 [00:16<01:53,  3.87it/s]\n",
      "Model No. xx:  12%|█▏        | 61/500 [00:16<01:56,  3.78it/s]\n",
      "Model No. xx:  13%|█▎        | 66/500 [00:16<01:49,  3.95it/s]\n",
      "Model No. xx:  22%|██▏       | 110/500 [00:25<01:29,  4.34it/s]\n",
      "Model No. xx:  23%|██▎       | 113/500 [00:26<01:30,  4.28it/s]\n",
      "Model No. xx:  26%|██▌       | 129/500 [00:28<01:21,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The R2 score for CARTE Singletable: 0.3493\n"
     ]
    }
   ],
   "source": [
    "# Set basic specifications\n",
    "data_name = \"wina_pl\"      # Name of the data\n",
    "num_train = 128     # Train-size\n",
    "random_state = 1    # Random_state\n",
    "\n",
    "# Load data and set train/test split\n",
    "data, data_config = _load_data(data_name)\n",
    "X_train_, X_test_, y_train, y_test = _set_split(\n",
    "    data,\n",
    "    data_config,\n",
    "    num_train,\n",
    "    random_state=random_state,\n",
    ")\n",
    "preprocessor = Table2GraphTransformer()\n",
    "X_train = preprocessor.fit_transform(X_train_, y=y_train)\n",
    "X_test = preprocessor.transform(X_test_)\n",
    "\n",
    "# Define some parameters\n",
    "fixed_params = dict()\n",
    "fixed_params[\"num_model\"] = 10 # 10 models for the bagging strategy\n",
    "fixed_params[\"disable_pbar\"] = False # True if you want cleanness\n",
    "fixed_params[\"random_state\"] = 0\n",
    "fixed_params[\"device\"] = \"cpu\"\n",
    "fixed_params[\"n_jobs\"] = 10\n",
    "\n",
    "# Define the estimator and run fit/predict\n",
    "estimator = CARTERegressor(**fixed_params) # CARTERegressor for Regression\n",
    "estimator.fit(X=X_train, y=y_train)\n",
    "y_pred = estimator.predict(X_test)\n",
    "\n",
    "# Obtain the r2 score on predictions\n",
    "score = r2_score(y_test, y_pred)\n",
    "print(f\"\\nThe R2 score for CARTE Singletable:\", \"{:.4f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we include a source data Wine Vivino, which contains information about wine bottles scrapped from Vivino’s website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "target_data_name = \"wina_pl\"\n",
    "source_data_name = [\"wine_vivino_price\"]\n",
    "num_train = 128\n",
    "random_state = 1\n",
    "\n",
    "# Load target data\n",
    "data_t, config_data_t = _load_data(target_data_name)\n",
    "\n",
    "# Load and prepare source data\n",
    "data_s_total = dict()\n",
    "config_data_s_total = dict()\n",
    "for data_name in source_data_name:\n",
    "    data_s, config_data_s = _load_data(data_name)\n",
    "    data_s_total[data_name] = data_s.copy()\n",
    "    config_data_s_total[data_name] = config_data_s\n",
    "\n",
    "Xt_carte_train, Xt_carte_test, Xs_carte, yt_train, yt_test = _prepare_carte(data_t, data_s_total, config_data_t, config_data_s_total, num_train, random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      " Name                          Pomerol 2011\n",
      "Region                     Pomerol, France\n",
      "Winery               Château La Providence\n",
      "Rating                                 4.2\n",
      "Number_Of_Ratings                    100.0\n",
      "Price                             4.553877\n",
      "Year                                  2011\n",
      "Wine_Type                              red\n",
      "Name: 0, dtype: object\n",
      "\n",
      "Graph Data:\n",
      " Data(x=[8, 300], edge_index=[2, 14], edge_attr=[14, 300], y=[1], g_idx=0, domain=1)\n"
     ]
    }
   ],
   "source": [
    "# Original source data\n",
    "print(\"Original Source Data:\\n\", data_s_total[\"wine_vivino_price\"].iloc[0])\n",
    "\n",
    "# Graph data\n",
    "print(\"\\nGraph Source Data:\\n\", Xs_carte[\"wine_vivino_price\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For learning, CARTE multitable also runs with the sklearn interface (fit/predict). CARTE multitable is similar to the singletable estimators with additional parameters of the source_data and target_fraction, which controls the fraction of target data when creating the batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that CARTE multitable estimator builds additional models, trained jointly with the source data, on top of the models from singletable (see our paper for more specific implementation details). The parameter \"num_model\" specifies for each case (wina_pl/wina_pl-wine_vivino_price in this case), resulting in 10 models for the bagging strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "Model No. xx:   1%|          | 3/500 [00:04<12:33,  1.52s/it]/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "Model No. xx:   2%|▏         | 8/500 [00:01<01:56,  4.22it/s]/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "Model No. xx:   7%|▋         | 37/500 [00:08<01:50,  4.21it/s]/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "Model No. xx:  10%|▉         | 49/500 [00:11<01:50,  4.09it/s]\n",
      "Model No. xx:   2%|▏         | 11/500 [00:02<01:40,  4.84it/s]/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "Model No. xx:   8%|▊         | 39/500 [00:09<01:42,  4.50it/s]/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "Model No. xx:   9%|▉         | 45/500 [00:10<01:48,  4.21it/s]\n",
      "Model No. xx:   3%|▎         | 13/500 [00:03<01:53,  4.28it/s]/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "Model No. xx:   7%|▋         | 37/500 [00:09<01:59,  3.87it/s]/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "Model No. xx:   9%|▉         | 47/500 [00:11<01:55,  3.93it/s]\n",
      "Model No. xx:   4%|▎         | 18/500 [00:04<01:46,  4.51it/s]/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "Model No. xx:   9%|▉         | 46/500 [00:10<01:47,  4.23it/s]\n",
      "Model No. xx:   9%|▉         | 44/500 [00:09<01:40,  4.53it/s]\n",
      "Model No. xx:  10%|▉         | 49/500 [01:19<12:10,  1.62s/it]\n",
      "Model No. xx:  13%|█▎        | 65/500 [01:43<11:32,  1.59s/it]\n",
      "Model No. xx:   9%|▉         | 47/500 [01:17<12:23,  1.64s/it]\n",
      "Model No. xx:  16%|█▌        | 80/500 [02:10<11:23,  1.63s/it]\n",
      "Model No. xx:  27%|██▋       | 134/500 [03:13<08:49,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The R2 for CARTE Multitable with additional Wine Vivino: 0.4024\n"
     ]
    }
   ],
   "source": [
    "fixed_params = dict()\n",
    "fixed_params[\"source_data\"] = Xs_carte\n",
    "fixed_params[\"num_model\"] = 5           # (10 models total wina_pl/wina_pl-wine_vivino_price)\n",
    "fixed_params[\"n_jobs\"] = 10\n",
    "fixed_params[\"random_state\"] = 0\n",
    "fixed_params[\"disable_pbar\"] = False\n",
    "\n",
    "estimator = CARTEMultitableRegressor(**fixed_params)\n",
    "estimator.fit(Xt_carte_train, yt_train)\n",
    "\n",
    "y_pred = estimator.predict(Xt_carte_test)\n",
    "\n",
    "# Obtain the r2 score on predictions\n",
    "score = r2_score(yt_test, y_pred)\n",
    "print(f\"\\nThe R2 for CARTE Multitable with additional Wine Vivino:\", \"{:.4f}\".format(score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For CARTE multitable estimator, it is also possible to include more than one source data.\n",
    "Let us run the case with two source data, Wine Vivino and Wine.com, which contains information on wines scraped from the wine.com website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "Model No. xx:   2%|▏         | 8/500 [00:11<10:20,  1.26s/it]/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "Model No. xx:   1%|          | 6/500 [00:09<12:51,  1.56s/it]]/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "Model No. xx:   8%|▊         | 42/500 [00:10<01:52,  4.07it/s]/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "Model No. xx:  10%|▉         | 49/500 [00:12<01:53,  3.98it/s]\n",
      "Model No. xx:   5%|▌         | 25/500 [00:39<12:26,  1.57s/it]/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "Model No. xx:  10%|▉         | 49/500 [01:09<10:38,  1.42s/it]\n",
      "Model No. xx:   1%|          | 6/500 [00:10<14:23,  1.75s/it]/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "Model No. xx:   7%|▋         | 35/500 [00:09<02:05,  3.71it/s]/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "Model No. xx:   9%|▉         | 45/500 [00:12<02:01,  3.74it/s]\n",
      "Model No. xx:   7%|▋         | 34/500 [00:54<12:36,  1.62s/it]/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "Model No. xx:  12%|█▏        | 61/500 [01:39<12:25,  1.70s/it]/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "Model No. xx:   7%|▋         | 33/500 [00:09<02:19,  3.35it/s]/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "Model No. xx:   9%|▉         | 47/500 [00:13<02:14,  3.37it/s]\n",
      "Model No. xx:  15%|█▌        | 77/500 [02:08<11:46,  1.67s/it]\n",
      "Model No. xx:  10%|▉         | 48/500 [01:27<13:31,  1.80s/it]/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "Model No. xx:  10%|▉         | 49/500 [01:30<13:56,  1.86s/it]\n",
      "Model No. xx:   9%|▉         | 47/500 [01:13<11:43,  1.55s/it]/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "Model No. xx:   9%|▉         | 46/500 [00:11<01:57,  3.85it/s]\n",
      "Model No. xx:   5%|▌         | 25/500 [00:43<14:07,  1.78s/it]/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "Model No. xx:  10%|█         | 52/500 [01:30<12:48,  1.71s/it]/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/data/parietal/store2/work/mkim/.local/miniconda3/envs/carte_test/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "Model No. xx:  11%|█         | 53/500 [01:33<13:12,  1.77s/it]\n",
      "Model No. xx:  17%|█▋        | 84/500 [02:15<11:09,  1.61s/it]]\n",
      "Model No. xx:   9%|▉         | 44/500 [00:10<01:52,  4.05it/s]\n",
      "Model No. xx:   9%|▉         | 47/500 [01:17<12:23,  1.64s/it]]\n",
      "Model No. xx:  13%|█▎        | 66/500 [01:52<12:20,  1.71s/it]]\n",
      "Model No. xx:  22%|██▏       | 111/500 [02:58<10:25,  1.61s/it]\n",
      "Model No. xx:  46%|████▌     | 229/500 [05:45<06:49,  1.51s/it]\n",
      "Model No. xx:  27%|██▋       | 136/500 [03:23<09:04,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The R2 for CARTE Multitable with additional Wine Vivino: 0.4437\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "target_data_name = \"wina_pl\"\n",
    "source_data_name = [\"wine_vivino_price\", \"wine_dot_com_prices\"]\n",
    "num_train = 128\n",
    "random_state = 1\n",
    "\n",
    "# Load target data\n",
    "data_t, config_data_t = _load_data(target_data_name)\n",
    "\n",
    "# Load and prepare source data\n",
    "data_s_total = dict()\n",
    "config_data_s_total = dict()\n",
    "for data_name in source_data_name:\n",
    "    data_s, config_data_s = _load_data(data_name)\n",
    "    data_s_total[data_name] = data_s.copy()\n",
    "    config_data_s_total[data_name] = config_data_s\n",
    "\n",
    "Xt_carte_train, Xt_carte_test, Xs_carte, yt_train, yt_test = _prepare_carte(data_t, data_s_total, config_data_t, config_data_s_total, num_train, random_state)\n",
    "\n",
    "fixed_params = dict()\n",
    "fixed_params[\"source_data\"] = Xs_carte\n",
    "fixed_params[\"num_model\"] = 5           # (15 models total with two sources)\n",
    "fixed_params[\"n_jobs\"] = 15\n",
    "fixed_params[\"random_state\"] = 0\n",
    "fixed_params[\"disable_pbar\"] = False\n",
    "\n",
    "estimator = CARTEMultitableRegressor(**fixed_params)\n",
    "estimator.fit(Xt_carte_train, yt_train)\n",
    "\n",
    "y_pred = estimator.predict(Xt_carte_test)\n",
    "\n",
    "# Obtain the r2 score on predictions\n",
    "score = r2_score(yt_test, y_pred)\n",
    "print(f\"\\nThe R2 for CARTE Multitable with two sources:\", \"{:.4f}\".format(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
