{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example for running CARTE on single tables\n",
    "In this example, we run CARTE on two datasets, one for regression and one for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the current working directory and import packages\n",
    "import os\n",
    "from pathlib import Path\n",
    "os.chdir(Path().cwd().parent)\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "from src.carte_table_to_graph import Table2GraphTransformer\n",
    "from src.carte_estimator import CARTERegressor, CARTEClassifier\n",
    "from configs.directory import config_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define necessary functions\n",
    "\n",
    "# Load data\n",
    "def _load_data(data_name):\n",
    "    data_pd_dir = f\"{config_directory['data_singletable']}/{data_name}/raw.parquet\"\n",
    "    data_pd = pd.read_parquet(data_pd_dir)\n",
    "    data_pd.fillna(value=np.nan, inplace=True)\n",
    "    config_data_dir = f\"{config_directory['data_singletable']}/{data_name}/config_data.json\"\n",
    "    filename = open(config_data_dir)\n",
    "    config_data = json.load(filename)\n",
    "    filename.close()\n",
    "    return data_pd, config_data\n",
    "\n",
    "# Set train/test split given the random state\n",
    "def _set_split(data, data_config, num_train, random_state):\n",
    "    target_name = data_config[\"target_name\"]\n",
    "    X = data.drop(columns=target_name)\n",
    "    y = data[target_name]\n",
    "    y = np.array(y)\n",
    "\n",
    "    if data_config[\"repeated\"]:\n",
    "        entity_name = data_config[\"entity_name\"]\n",
    "    else:\n",
    "        entity_name = np.arange(len(y))\n",
    "\n",
    "    groups = np.array(data.groupby(entity_name).ngroup())\n",
    "    num_groups = len(np.unique(groups))\n",
    "    gss = GroupShuffleSplit(\n",
    "        n_splits=1,\n",
    "        test_size=int(num_groups - num_train),\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    idx_train, idx_test = next(iter(gss.split(X=y, groups=groups)))\n",
    "\n",
    "    X_train, X_test = X.iloc[idx_train], X.iloc[idx_test]\n",
    "    y_train, y_test = y[idx_train], y[idx_test]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first run an example of a regression task. The dataset we will be using is the Wine Poland dataset, which contains information about wines on the polish market. The task is to predict the price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic preparations are:\n",
    "- set basic specifications\n",
    "- load the prepared data and configs; set train/test split\n",
    "- generate graphs for each table entries (rows) using the Table2GraphTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set basic specifications\n",
    "data_name = \"wina_pl\"      # Name of the data\n",
    "num_train = 128     # Train-size\n",
    "random_state = 3    # Random_state\n",
    "\n",
    "# Load data and set train/test split\n",
    "data, data_config = _load_data(data_name)\n",
    "X_train_, X_test_, y_train, y_test = _set_split(\n",
    "    data,\n",
    "    data_config,\n",
    "    num_train,\n",
    "    random_state=random_state,\n",
    ")\n",
    "preprocessor = Table2GraphTransformer()\n",
    "X_train = preprocessor.fit_transform(X_train_, y=y_train)\n",
    "X_test = preprocessor.transform(X_test_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARTE currently runs with the sklearn interface (fit/predict) and the process is:\n",
    "- Define parameters\n",
    "- Set the estimator\n",
    "- Run 'fit' to train the model and 'predict' to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model No. xx:   9%|▊         | 43/500 [00:12<02:14,  3.39it/s]\n",
      "Model No. xx:  10%|▉         | 48/500 [00:13<02:06,  3.58it/s]\n",
      "Model No. xx:  11%|█         | 54/500 [00:15<02:07,  3.50it/s]\n",
      "Model No. xx:  12%|█▏        | 58/500 [00:16<02:09,  3.42it/s]\n",
      "Model No. xx:  12%|█▏        | 58/500 [00:16<02:03,  3.57it/s]\n",
      "Model No. xx:  13%|█▎        | 67/500 [00:18<01:58,  3.65it/s]\n",
      "Model No. xx:  14%|█▍        | 71/500 [00:18<01:51,  3.86it/s]\n",
      "Model No. xx:  13%|█▎        | 67/500 [00:18<01:56,  3.71it/s]\n",
      "Model No. xx:  13%|█▎        | 66/500 [00:18<02:03,  3.50it/s]\n",
      "Model No. xx:  15%|█▍        | 73/500 [00:20<01:57,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The R2 score for CARTE: 0.4243\n"
     ]
    }
   ],
   "source": [
    "# Define some parameters\n",
    "fixed_params = dict()\n",
    "fixed_params[\"loss\"] = \"squared_error\"\n",
    "fixed_params[\"scoring\"] = \"r2_score\"\n",
    "fixed_params[\"learning_rate\"] = 2.5e-4\n",
    "fixed_params[\"max_epoch\"] = 500\n",
    "fixed_params[\"early_stopping_patience\"] = 40\n",
    "fixed_params[\"val_size\"] = 0.2\n",
    "fixed_params[\"cross_validate\"] = True\n",
    "fixed_params[\"batch_size\"] = 16\n",
    "fixed_params[\"dropout\"] = 0\n",
    "fixed_params[\"num_model\"] = 10 # 10 models for the bagging strategy\n",
    "fixed_params[\"load_pretrain\"] = True\n",
    "fixed_params[\"freeze_pretrain\"] = True\n",
    "fixed_params[\"num_layers\"] = 1\n",
    "fixed_params[\"disable_pbar\"] = False # True if you want cleanness\n",
    "fixed_params[\"random_state\"] = 0\n",
    "fixed_params[\"device\"] = \"cpu\"\n",
    "fixed_params[\"n_jobs\"] = 10\n",
    "\n",
    "# Define the estimator and run fit/predict\n",
    "estimator = CARTERegressor(**fixed_params) # CARTERegressor for Regression\n",
    "estimator.fit(X=X_train, y=y_train)\n",
    "y_pred = estimator.predict(X_test)\n",
    "\n",
    "# Obtain the r2 score on predictions\n",
    "score = r2_score(y_test, y_pred)\n",
    "print(f\"\\nThe R2 score for CARTE:\", \"{:.4f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification, the dataset we will be using is the Spotify dataset, which contains generic information on Spotify tracks with some associated audio features. The task is to predict the popularity of the albums.\n",
    "\n",
    "The procedure will be similar to regression with the difference only in defining the parameters, performance measurements (AUROC), and 'predict_proba' (instead of fit since we are using AUROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set basic specifications\n",
    "data_name = \"spotify\"      # Name of the data\n",
    "num_train = 128     # Train-size\n",
    "random_state = 3    # Random_state\n",
    "\n",
    "# Load data and set train/test split\n",
    "data, data_config = _load_data(data_name)\n",
    "X_train_, X_test_, y_train, y_test = _set_split(\n",
    "    data,\n",
    "    data_config,\n",
    "    num_train,\n",
    "    random_state=random_state,\n",
    ")\n",
    "preprocessor = Table2GraphTransformer()\n",
    "X_train = preprocessor.fit_transform(X_train_, y=y_train)\n",
    "X_test = preprocessor.transform(X_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model No. xx:   9%|▉         | 44/500 [00:15<02:38,  2.88it/s]\n",
      "Model No. xx:  10%|▉         | 49/500 [00:15<02:24,  3.13it/s]\n",
      "Model No. xx:   9%|▉         | 44/500 [00:15<02:45,  2.75it/s]\n",
      "Model No. xx:  11%|█         | 53/500 [00:16<02:18,  3.22it/s]\n",
      "Model No. xx:  12%|█▏        | 59/500 [00:18<02:19,  3.16it/s]\n",
      "Model No. xx:  11%|█         | 54/500 [00:18<02:35,  2.87it/s]\n",
      "Model No. xx:  11%|█         | 56/500 [00:19<02:37,  2.82it/s]\n",
      "Model No. xx:  13%|█▎        | 66/500 [00:20<02:16,  3.19it/s]\n",
      "Model No. xx:  15%|█▌        | 76/500 [00:23<02:10,  3.25it/s]\n",
      "Model No. xx:  18%|█▊        | 92/500 [00:25<01:53,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The AUROC for CARTE: 0.8718\n"
     ]
    }
   ],
   "source": [
    "# Define some parameters\n",
    "fixed_params = dict()\n",
    "fixed_params[\"loss\"] = \"binary_crossentropy\"\n",
    "fixed_params[\"scoring\"] = \"auroc\"\n",
    "fixed_params[\"learning_rate\"] = 1e-3\n",
    "fixed_params[\"max_epoch\"] = 500\n",
    "fixed_params[\"early_stopping_patience\"] = 40\n",
    "fixed_params[\"val_size\"] = 0.2\n",
    "fixed_params[\"cross_validate\"] = False\n",
    "fixed_params[\"batch_size\"] = 16\n",
    "fixed_params[\"dropout\"] = 0\n",
    "fixed_params[\"num_model\"] = 10 # 10 models for the bagging strategy\n",
    "fixed_params[\"load_pretrain\"] = True\n",
    "fixed_params[\"freeze_pretrain\"] = True\n",
    "fixed_params[\"num_layers\"] = 1\n",
    "fixed_params[\"disable_pbar\"] = False # True if you want cleanness\n",
    "fixed_params[\"random_state\"] = 0\n",
    "fixed_params[\"device\"] = \"cpu\"\n",
    "fixed_params[\"n_jobs\"] = 10\n",
    "\n",
    "# Define the estimator and run fit/predict\n",
    "estimator = CARTEClassifier(**fixed_params) # CARTERegressor for Regression\n",
    "estimator.fit(X=X_train, y=y_train)\n",
    "y_pred = estimator.predict_proba(X_test)\n",
    "\n",
    "# Obtain the r2 score on predictions\n",
    "score = roc_auc_score(y_test, y_pred)\n",
    "print(f\"\\nThe AUROC for CARTE:\", \"{:.4f}\".format(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
