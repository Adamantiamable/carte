{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example for running CARTE on single tables\n",
    "In this example, we run CARTE on two datasets, one for regression and one for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the current working directory and import packages\n",
    "import os\n",
    "from pathlib import Path\n",
    "os.chdir(Path().cwd().parent)\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "from src.carte_table_to_graph import Table2GraphTransformer\n",
    "from src.carte_estimator import CARTERegressor, CARTEClassifier\n",
    "from configs.directory import config_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define necessary functions\n",
    "\n",
    "def _load_data(data_name):\n",
    "    \"\"\"Load the preprocessed data.\"\"\"\n",
    "    data_pd_dir = f\"{config_directory['data_singletable']}/{data_name}/raw.parquet\"\n",
    "    data_pd = pd.read_parquet(data_pd_dir)\n",
    "    data_pd.fillna(value=np.nan, inplace=True)\n",
    "    config_data_dir = f\"{config_directory['data_singletable']}/{data_name}/config_data.json\"\n",
    "    filename = open(config_data_dir)\n",
    "    config_data = json.load(filename)\n",
    "    filename.close()\n",
    "    return data_pd, config_data\n",
    "\n",
    "def _set_split(data, data_config, num_train, random_state):\n",
    "    \"\"\"Set train/test split given the random state.\"\"\"\n",
    "    target_name = data_config[\"target_name\"]\n",
    "    X = data.drop(columns=target_name)\n",
    "    y = data[target_name]\n",
    "    y = np.array(y)\n",
    "\n",
    "    if data_config[\"repeated\"]:\n",
    "        entity_name = data_config[\"entity_name\"]\n",
    "    else:\n",
    "        entity_name = np.arange(len(y))\n",
    "\n",
    "    groups = np.array(data.groupby(entity_name).ngroup())\n",
    "    num_groups = len(np.unique(groups))\n",
    "    gss = GroupShuffleSplit(\n",
    "        n_splits=1,\n",
    "        test_size=int(num_groups - num_train),\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    idx_train, idx_test = next(iter(gss.split(X=y, groups=groups)))\n",
    "\n",
    "    X_train, X_test = X.iloc[idx_train], X.iloc[idx_test]\n",
    "    y_train, y_test = y[idx_train], y[idx_test]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first run an example of a regression task. The dataset we will be using is the Wine Poland dataset, which contains information about wines on the polish market. The task is to predict the price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic preparations are:\n",
    "- preprocess raw data\n",
    "- load the prepared data and configs; set train/test split\n",
    "- generate graphs for each table entries (rows) using the Table2GraphTransformer\n",
    "- create an estimator and make inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The codes for preprocessing is provided in scripts/preprocess_raw.py. Here, we directly use the transformed data, which should be in data/data_singletable if you have successfully downloaded it with the instructions.\n",
    "\n",
    "We transform each data point (row) with the Table2GraphTransformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set basic specifications\n",
    "data_name = \"wina_pl\"      # Name of the data\n",
    "num_train = 128     # Train-size\n",
    "random_state = 1    # Random_state\n",
    "\n",
    "# Load data and set train/test split\n",
    "data, data_config = _load_data(data_name)\n",
    "X_train_, X_test_, y_train, y_test = _set_split(\n",
    "    data,\n",
    "    data_config,\n",
    "    num_train,\n",
    "    random_state=random_state,\n",
    ")\n",
    "preprocessor = Table2GraphTransformer()\n",
    "X_train = preprocessor.fit_transform(X_train_, y=y_train)\n",
    "X_test = preprocessor.transform(X_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      " name                   Achillée Crémant Soléra AOC Crémant d'Alsace NV\n",
      "country                                                         France\n",
      "region                                                          Alsace\n",
      "appellation                                       Cremant d'Alsace AOC\n",
      "vineyard                                                      Achillée\n",
      "vintage                                                            NaN\n",
      "volume                                                           750.0\n",
      "ABV                                                               13.5\n",
      "serving_temperature                                                  9\n",
      "wine_type                                                          NaN\n",
      "taste                                                              dry\n",
      "style                                                          average\n",
      "vegan                                                            False\n",
      "natural                                                           True\n",
      "grapes                                            Pinot Gris, Sylvaner\n",
      "Name: 15, dtype: object\n",
      "\n",
      "Graph Data:\n",
      " Data(x=[14, 300], edge_index=[2, 26], edge_attr=[26, 300], y=[1], g_idx=0)\n"
     ]
    }
   ],
   "source": [
    "# Original data\n",
    "print(\"Original Data:\\n\", X_train_.iloc[0])\n",
    "\n",
    "# Graph data\n",
    "print(\"\\nGraph Data:\\n\", X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a list of graph objects which can be used as inputs for the neural network in CARTE.\n",
    "\n",
    "Each row is transformed into a graph data with node features(x), edge index (the graph structure), edge features, and the target y (not visible in the test set).\n",
    "\n",
    "Also, this data point contains 13 columns (out of 15) which are not missing. Thus, the resulting graph will contain 14 node features (13 columns and center node), and 26 edge features (13 columns and 13 self-loops), as the graph is directed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For learning, CARTE currently runs with the sklearn interface (fit/predict) and the process is:\n",
    "- Define parameters\n",
    "- Set the estimator\n",
    "- Run 'fit' to train the model and 'predict' to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model No. xx:   9%|▉         | 46/500 [01:21<13:23,  1.77s/it]\n",
      "Model No. xx:  10%|█         | 51/500 [01:26<12:37,  1.69s/it]\n",
      "Model No. xx:  10%|█         | 51/500 [01:26<12:42,  1.70s/it]\n",
      "Model No. xx:  11%|█         | 54/500 [01:27<12:02,  1.62s/it]\n",
      "Model No. xx:  12%|█▏        | 61/500 [01:31<10:59,  1.50s/it]\n",
      "Model No. xx:  12%|█▏        | 62/500 [01:32<10:50,  1.48s/it]\n",
      "Model No. xx:  13%|█▎        | 66/500 [01:33<10:12,  1.41s/it]\n",
      "Model No. xx:  20%|█▉        | 98/500 [01:41<06:57,  1.04s/it]]\n",
      "Model No. xx:  23%|██▎       | 114/500 [01:45<05:55,  1.09it/s]\n",
      "Model No. xx:  22%|██▏       | 112/500 [01:45<06:06,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The R2 score for CARTE: 0.3460\n"
     ]
    }
   ],
   "source": [
    "# Define some parameters\n",
    "fixed_params = dict()\n",
    "fixed_params[\"num_model\"] = 10 # 10 models for the bagging strategy\n",
    "fixed_params[\"disable_pbar\"] = False # True if you want cleanness\n",
    "fixed_params[\"random_state\"] = 0\n",
    "fixed_params[\"device\"] = \"cpu\"\n",
    "fixed_params[\"n_jobs\"] = 10\n",
    "\n",
    "# Define the estimator and run fit/predict\n",
    "estimator = CARTERegressor(**fixed_params) # CARTERegressor for Regression\n",
    "estimator.fit(X=X_train, y=y_train)\n",
    "y_pred = estimator.predict(X_test)\n",
    "\n",
    "# Obtain the r2 score on predictions\n",
    "score = r2_score(y_test, y_pred)\n",
    "print(f\"\\nThe R2 score for CARTE:\", \"{:.4f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification, the dataset we will be using is the Spotify dataset, which contains generic information on Spotify tracks with some associated audio features. The task is to predict the popularity of the albums.\n",
    "\n",
    "The procedure will be similar to regression with the difference only in defining the parameters, performance measurements (AUROC), and 'predict_proba' (instead of fit since we are using AUROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set basic specifications\n",
    "data_name = \"spotify\"      # Name of the data\n",
    "num_train = 128     # Train-size\n",
    "random_state = 1    # Random_state\n",
    "\n",
    "# Load data and set train/test split\n",
    "data, data_config = _load_data(data_name)\n",
    "X_train_, X_test_, y_train, y_test = _set_split(\n",
    "    data,\n",
    "    data_config,\n",
    "    num_train,\n",
    "    random_state=random_state,\n",
    ")\n",
    "preprocessor = Table2GraphTransformer()\n",
    "X_train = preprocessor.fit_transform(X_train_, y=y_train)\n",
    "X_test = preprocessor.transform(X_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model No. xx:  11%|█         | 53/500 [01:27<12:19,  1.66s/it]\n",
      "Model No. xx:  10%|█         | 50/500 [01:32<13:51,  1.85s/it]\n",
      "Model No. xx:  12%|█▏        | 60/500 [01:41<12:24,  1.69s/it]\n",
      "Model No. xx:  13%|█▎        | 63/500 [01:42<11:50,  1.63s/it]\n",
      "Model No. xx:  13%|█▎        | 64/500 [01:42<11:40,  1.61s/it]\n",
      "Model No. xx:  12%|█▏        | 61/500 [01:43<12:24,  1.70s/it]\n",
      "Model No. xx:  13%|█▎        | 65/500 [01:43<11:32,  1.59s/it]\n",
      "Model No. xx:  14%|█▍        | 71/500 [01:45<10:39,  1.49s/it]\n",
      "Model No. xx:  14%|█▍        | 70/500 [01:46<10:56,  1.53s/it]\n",
      "Model No. xx:  14%|█▍        | 72/500 [01:47<10:36,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The AUROC for CARTE: 0.8864\n"
     ]
    }
   ],
   "source": [
    "# Define some parameters\n",
    "fixed_params = dict()\n",
    "fixed_params[\"num_model\"] = 10 # 10 models for the bagging strategy\n",
    "fixed_params[\"disable_pbar\"] = False # True if you want cleanness\n",
    "fixed_params[\"random_state\"] = 0\n",
    "fixed_params[\"device\"] = \"cpu\"\n",
    "fixed_params[\"n_jobs\"] = 10\n",
    "\n",
    "# Define the estimator and run fit/predict\n",
    "estimator = CARTEClassifier(**fixed_params) # CARTERegressor for Regression\n",
    "estimator.fit(X=X_train, y=y_train)\n",
    "y_pred = estimator.predict_proba(X_test)\n",
    "\n",
    "# Obtain the r2 score on predictions\n",
    "score = roc_auc_score(y_test, y_pred)\n",
    "print(f\"\\nThe AUROC for CARTE:\", \"{:.4f}\".format(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
