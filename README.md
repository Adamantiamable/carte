# CARTE: <br />Pretraining and Transfer for Tabular Learning

(The repo is still under construction, it will be available as soon a possible)

This repository contains the implementation of the paper CARTE: Pretraining and Transfer for Tabular Learning.

<!-- training a foundation model for tabular data by treating each table row as a star graph and training a graph transformer on top of this representation.
-->

## Installation

**Requried packages**

<!-- - Installation of packages
- Downloading datasets and langauge models
- Only for CARTE:
- Optional:
-->

**Downloading data**

- Fasttext
- Ken Embeddings

## Getting started

**Running CARTE for singletables**

**Running CARTE for multitables**
We recommend

Running CARTE for multitables with number of sources under 2 is not rec

## Reproducing results of CARTE paper

Under ... it contains the parameters from random search of 100 iterations. To

## Our paper

```
@article{kim2024carte,
  title={CARTE: pretraining and transfer for tabular learning},
  author={Kim, Myung Jun and Grinsztajn, L{\'e}o and Varoquaux, Ga{\"e}l},
  journal={arXiv preprint arXiv:2402.16785},
  year={2024}
}
```
